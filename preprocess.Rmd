---
title: "preprocessing"
author: "Peter Hahn"
date: "11 11 2018"
output: html_document
---
## all stuff for running of juli_stm and app because loading of data and stm processing take to much time


```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = FALSE, include = TRUE, message=FALSE, fig.width = 12, fig.height = 8)
## load libraries
library(tidyverse)
library(RISmed)
library(wordcloud)
library(stringr)
library(tm)
library(tidytext)
library(widyr)
library(topicmodels)
library(furrr)
library(stm)
```

## routine for loading new query use saved * csv instead 
```{r}
        res1 <- EUtilsSummary("Dupuytren Contracture[Mesh]" , 
                      type = "esearch", 
                      db = "pubmed",
                      datetype = "pdat",
                      retmax = 12000,
                      mindate = 1960, 
                      maxdate = 2018)

        fetch <- EUtilsGet(res1, type = "efetch", db = "pubmed")

        abstracts <- data.frame(title = fetch@ArticleTitle,
                                abstract = fetch@AbstractText, 
                                journal = fetch@Title,
                                DOI = fetch@PMID, 
                                year = fetch@YearPubmed)
        ## ensure abstracts are character fields (not factors)
        abstracts <- abstracts %>% mutate(abstract = as.character(abstract))
        # make bins for publication year
        abstracts$year_cut <- cut(abstracts$year, c(1960, 1970, 1980, 1990, 2000,2010,2018),labels=c("60-69","70-79","80-89","90-99","00-09","10-18"), include.lowest=TRUE)

        ## remove plural words
       pm_data <-pm_data  %>% mutate(abstract=str_replace_all(abstract,"options","option")) 
# list of words to remove in token
        del_word <-  tibble(word=c("dupuytren","NA","patient","disease","treatment","study","result","hand","disease",
                                "contracture","patients","dupuytren's","clinical","results","report","included","month","treated","found","increased","compared","95","ci","10","20","30","statistically","lt","studies","underwent","diagnosis","12","15","50","reported","de","quot","des","bev","major","dd"))
        
```

```{r}
         pm_abstract <- pm_data %>% 
                unnest_tokens(word,abstract) %>% 
                anti_join(stop_words)  %>% anti_join(del_word)
```

### make sparse matrix and 

```{r}
        ```{r}
        word_counts <- pm_abstract %>% 
        count(DOI,word,sort=TRUE) %>% ungroup()
```

make document term matrix
```{r}
        abstr_sparse <- word_counts %>% 
                cast_sparse(DOI,word,n)
```

### Calculate multi topic stm and evaluate
```{r}
### calculate stm

```{r}
plan(multiprocess)

many_models <- data_frame(K = c(20,30,40,50,60,70)) %>%
  mutate(topic_model = future_map(K, ~stm(abstr_sparse, K = .,
                                          verbose = FALSE)))
```

## evaluate

```{r}
        heldout <- make.heldout(abstr_sparse)

k_result <- many_models %>%
  mutate(exclusivity = map(topic_model, exclusivity),
         semantic_coherence = map(topic_model, semanticCoherence, abstr_sparse),
         eval_heldout = map(topic_model, eval.heldout, heldout$missing),
         residual = map(topic_model, checkResiduals, abstr_sparse),
         bound =  map_dbl(topic_model, function(x) max(x$convergence$bound)),
         lfact = map_dbl(topic_model, function(x) lfactorial(x$settings$dim$K)),
         lbound = bound + lfact,
         iterations = map_dbl(topic_model, function(x) length(x$convergence$bound)))

k_result
```

# plot

```{r}
        k_result %>%
  transmute(K,
            `Lower bound` = lbound,
            Residuals = map_dbl(residual, "dispersion"),
            `Semantic coherence` = map_dbl(semantic_coherence, mean),
            `Held-out likelihood` = map_dbl(eval_heldout, "expected.heldout")) %>%
  gather(Metric, Value, -K) %>%
  ggplot(aes(K, Value, color = Metric)) +
  geom_line(size = 1.5, alpha = 0.7, show.legend = FALSE) +
  facet_wrap(~Metric, scales = "free_y") +
  labs(x = "K (number of topics)",
       y = NULL,
       title = "Model diagnostics by number of topics",
       subtitle = "These diagnostics indicate that a good number of topics would be around 60")
```

## make final model after evaluation with k = 60

```{r}
topic_model <- stm(abstr_sparse, K = 60, 
                   verbose = FALSE, init.type = "Spectral")
```

```{r}
        ##save if necessary or load
        # save(topic_model,file="topic_60.RData")
         tidy_stm <- tidy(topic_model)
```
```


